---
title: "GB Search Task (E2) OPAM Analyses"
author: "Dave Braun"
date: "08/10/2022"
output: 
  html_document:
    code_folding: hide
    df_print: paged
    theme: flatly
    includes:
      after_body: ../../../../../../html/footer.html
    
knit:
  (function(inputFile, encoding) {
      rmarkdown::render(inputFile,
                    encoding = encoding,
                    output_file = 'index.html')})
---

This document was last updated at `r Sys.time()`.

The big effects of interest:  

  * Quadrant bias  
  
```{r include = FALSE}
library(tidyverse)
library(testit)
library(psycho)
```

  
  
```{r}
d <- read.csv('../../data/exp2_long_data.csv')
thinnest_lines <- read.csv('../../data/exp2_thinnest_lines.csv')
line_data <- read.csv('../../data/exp2_line_data.csv')
head(d)
N <- length(unique(d$participant))
```

**There were `r N` participants in this study.**
  
```{r}
source('../compute_accuracy_columns.r')

result <- compute_accuracy_columns(d, thinnest_lines)
d <- result[[1]]
thinnest_lines <- result[[2]]

```
  
```{r}
## a function for spot checking accuracy coding throughout the data
spot_check <- function() {
  participant <- sample(d$participant, size = 1)
  trial <- sample(d[d$participant==participant,]$trial_count, size = 1)
  d_sub <- d[d$participant == participant & d$trial_count == trial,]
  t_sub <- thinnest_lines[thinnest_lines$participant == participant & thinnest_lines$trial_count == trial,]
  print('Subset of long data:')
  print(d_sub[,c('line_id', 'selected_or_released', 'accuracy_type')])
  print(' ')
  print(' ')
  print('Subset of thinnest lines data:')
  print(t_sub[,c('line_width', 'line_id', 'accuracy_type')])
}
## Anything coded as a "hit" in the long data should be represented in the thinnest lines data
## Anything coded as a "false alarm" shouldn't be represented in the thinnest lines data
spot_check()
```
  
## Quadrant Analysis

  
We'll calculate the center of the grid by looking at the most extreme X's and Y's and taking the center, then compare the center of the lines against that center point.
  
  
```{r}
line_data <- read.csv('../../data/exp2_line_data.csv')
head(line_data)
```

  
```{r}
top_left <- c(min(line_data$top_x), max(line_data$top_y))
top_right <- c(max(line_data$top_x), max(line_data$top_y))
bottom_left <- c(min(line_data$bottom_x), min(line_data$bottom_y))
bottom_right <- c(max(line_data$bottom_x), min(line_data$bottom_y))
print(top_left)
print(top_right)
print(bottom_left)
print(bottom_right)
```

```{r}
center <- c(mean(c(top_left[1], top_right[1])), mean(c(top_left[2], bottom_left[2])))
center
```


```{r}
source('../compute_quadrants.r')
## calculate line centers

d <- d %>% 
  mutate(line_center_x = (top_x + bottom_x) / 2, line_center_y = (top_y + bottom_y) / 2) %>% 
  mutate(quadrant = ifelse(line_center_x > center[1] & line_center_y > center[2], 'I', ifelse(line_center_x < center[1] & line_center_y > center[2], 'II',
                    ifelse(line_center_x < center[1] & line_center_y < center[2], 'III', ifelse(line_center_x > center[1] & line_center_y < center[2], 'IV', '')))))
line_data <- line_data %>% 
  mutate(line_center_x = (top_x + bottom_x) / 2, line_center_y = (top_y + bottom_y) / 2) %>% 
  mutate(quadrant = ifelse(line_center_x > center[1] & line_center_y > center[2], 'I', ifelse(line_center_x < center[1] & line_center_y > center[2], 'II',
                    ifelse(line_center_x < center[1] & line_center_y < center[2], 'III', ifelse(line_center_x > center[1] & line_center_y < center[2], 'IV', '')))))

## append line coordinates to thinnest lines data (for including misses in summarization)

line_data %>% 
  filter(participant == 27, trial_count == 1, is_exterior == 'False', line_orientation != 'vertical') %>% 
  mutate(x_dist = abs(line_center_x - center[1]), y_dist = abs(line_center_y - center[2])) %>% 
  mutate(is_on_axis = ifelse(x_dist < 0.1, 'y_axis', ifelse(y_dist < 0.1, 'x_axis', ''))) %>% 
  mutate(quadrant = ifelse(is_on_axis == '', quadrant, is_on_axis)) %>% 
  group_by(quadrant) %>% 
  summarize(count = n()) %>% 
  ggplot(aes(x = quadrant, y = count)) + 
  geom_bar(stat = 'identity') + 
  labs(
    x = 'Quadrant',
    y = 'Number of Lines per Trial'
  ) + 
  theme_bw()

ggsave('lines_per_quadrant.png', height = 1080 / 300, width = 1920 / 300, units = 'in', dpi = 300)

d <- d %>% 
  mutate(x_dist = abs(line_center_x - center[1]), y_dist = abs(line_center_y - center[2])) %>% 
  mutate(is_on_axis = ifelse(x_dist < 0.1, 'y_axis', ifelse(y_dist < 0.1, 'x_axis', ''))) %>% 
  mutate(quadrant = ifelse(is_on_axis == '', quadrant, is_on_axis)) 
  
clean_data <- d %>%   
  filter(!(is.na(quadrant)), !(is.na(accuracy_type)), line_orientation != 'vertical') %>% 
  group_by(participant, quadrant) %>% 
  summarize(count = n()) %>% 
  ## im not sure whether this makes sense
  mutate(proportion = ifelse(quadrant == 'x_axis', count / (6*300), count / (3*300))) 

write.csv(clean_data, 'exp2_quadrant_by_subject.csv', row.names = FALSE)

clean_data %>% 
  group_by(quadrant) %>% 
  ## add in SEs
  summarize(mean_proportion = mean(proportion), se = sd(proportion) / sqrt(N)) %>% 
  ggplot(aes(x = quadrant, y = mean_proportion)) +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = mean_proportion - se, ymax = mean_proportion + se), width = .5) + 
  labs(
    x = 'Quadrant',
    y = 'Mean Proportion Selection'
  ) + 
  theme_bw()

ggsave('selection_by_quadrant.png', height = 1080 / 300, width = 1920 / 300, units = 'in', dpi = 300)



```
All plots are excluding vertical lines.
  
  The way proportion selection is being calculated is as `number of selected lines in quadrant / total number of lines in the quadrant * total number of line selections (300)`.
  
  
```{r}
d %>% 
  filter(!(is.na(quadrant)), !(is.na(top_x)), !(is.na(accuracy_type)), line_orientation != 'vertical') %>% 
  group_by(participant, quadrant, accuracy_type) %>% 
  summarize(count = n()) %>% 
  spread(accuracy_type, count) %>% 
  mutate(hit_rate = hit / (hit + false_alarm)) %>% 
  mutate(d_prime = qnorm(hit_rate) - qnorm(1 - hit_rate)) %>%  
  group_by(quadrant) %>% 
  summarize(mean_dprime = mean(d_prime, na.rm = TRUE), se = sd(d_prime, na.rm = TRUE) / sqrt(N)) %>% 
  print() %>% 
  ggplot(aes(x = quadrant, y = mean_dprime)) +
  geom_bar(stat = 'identity', position = position_dodge(width = .9)) + 
  geom_errorbar(aes(ymin = mean_dprime - se, ymax = mean_dprime + se), width = .5, position = position_dodge(.9)) + 
  labs(
    x = 'Quadrant',
    y = 'd prime'
  ) + 
  theme_bw() + 
  theme(legend.position = 'bottom')

ggsave('accuracy_by_quadrant.png', height = 1080 / 300, width = 1920 / 300, units = 'in', dpi = 300)
```
  ^ Also excluding vertical lines.

 d prime was calculated at the subject level for each quadrant by first calculating hit rate per quadrant as `hit_rate = hits / (hits + false_alarms)`, `falsealarm_rate = 1 - hit_rate`, and d prime as `d_prime = qnorm(hit_rate) - qnorm(falsealarm_rate)`, and then averaging d prime across subjects.
 
 I'm not sure that my way of calculating hit rate was the best. It's pretty difficult to think about what the denominator for any proportion should be in this paradigm because, for example, accuracy is defined at the level of each line and not at the overall trial level.
  
  
    
## Line Clicking

```{r}
library(tidyverse)
library(data.table)
library(ggridges)
d <- read.csv('../../data/exp2_long_data.csv')
thinnest_lines <- read.csv('../../data/exp2_thinnest_lines.csv')
if (!'accuracy_type' %in% colnames(d)) {
  source('../compute_accuracy_columns.r')
  d <- compute_accuracy_columns(d, thinnest_lines)
  
}

N <- length(unique(d$participant))  
head(d)

colnames(d)[which(colnames(d) == 'participant')] <- 'subject'

click_summary <- d %>% 
  group_by(subject, trial_count) %>% 
  summarize(count = n()) %>% 
  filter(count == 4) %>% 
  select(-count) %>% 
  mutate(key = 'keep')

d <- d %>% 
  inner_join(click_summary) %>% 
  filter(key == 'keep', is.na(accuracy)) %>% 
  select(-key)

d$selection_rt_ms_relative <- ifelse(shift(d$click_order) < d$click_order, d$selection_rt_ms - shift(d$selection_rt_ms), d$selection_rt_ms)
d$selection_rt_ms_relative[1] <- d$selection_rt_ms[1]
d$accuracy_numeric <- ifelse(d$accuracy_type == 'hit', 1, 0)

write.csv(d, 'exp2_trial_clicking.csv', row.names = FALSE)

subject_summary <- d %>% 
  group_by(subject, click_order) %>% 
  summarize(RT = mean(selection_rt_ms_relative), Accuracy = mean(accuracy_numeric)) 

write.csv(subject_summary, 'exp2_group_clicking.csv', row.names = FALSE)

subject_summary %>% 
  gather(outcome, value, RT:Accuracy) %>% 
  ggplot(aes(x = value, y = click_order, group = click_order)) + 
  geom_density_ridges(fill = 'steel blue', alpha = .8) + 
  facet_wrap(~outcome, scales = 'free') + 
  labs(
    x = '',
    y = 'Click Order'
  ) + 
  theme_bw() + 
  theme(strip.background = element_rect(color = 'black', fill = 'white'))
```
  
  
```{r}
## this computation includes in selection time the time it took them to press the submit button
## also im including line releases
d <- read.csv('../../data/exp2_long_data.csv')
colnames(d)[colnames(d) == 'participant'] <- 'subject'
out <- d %>% 
  group_by(subject) %>% 
  summarize(prompt_rt_sec = mean(prompt_rt_sec), selection_rt_ms = mean(selection_rt_ms), accuracy = mean(accuracy, na.rm = TRUE)) 

write.csv(out, 'exp2_individual_clicking.csv', row.names = FALSE)

out %>% 
  ggplot(aes(x = selection_rt_ms/1000, y = prompt_rt_sec)) + 
  geom_point(aes(color = accuracy)) + 
  labs(
    x = 'Line Selection RT (s)',
    y = 'View Period RT (s)',
    color = 'Accuracy',
    caption = 'Each point represents one participant'
  ) +
  theme_bw()
```
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  